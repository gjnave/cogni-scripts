{
  "id": "9ae6082b-c7f4-433c-9971-7a8f65a3ea65",
  "revision": 0,
  "last_node_id": 75,
  "last_link_id": 85,
  "nodes": [
    {
      "id": 70,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        1035.3335842921224,
        -158.6666723932416
      ],
      "size": [
        310,
        50
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 71
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            74
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        3
      ]
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1380.333488730243,
        -38.66666495334084
      ],
      "size": [
        740,
        595
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 79
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "SaveImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "z-image"
      ]
    },
    {
      "id": 67,
      "type": "CLIPTextEncode",
      "pos": [
        585.3334160505818,
        -118.6667011003664
      ],
      "size": [
        410,
        315
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 78
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            75
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "A fashion photography work full of surreal romanticism, using a low-angle upward shooting composition, with a clear light blue sky as the background, and the visual focus concentrated on the fantasy blue vegetation and the model walking through it.\n\nThe vegetation in the picture is processed into varying shades of blue, from light ice blue to deep cobalt blue. The textures of the leaves and branches are delicate and realistic. The warm brown tree trunks form a sharp contrast with the cool blue leaves, resembling a dreamy forest from another world. An African-American model wearing a yellow and white vertical striped long dress walks slowly on the sand. The warm tones of the dress echo with the surrounding cool blue vegetation. The noon sun casts clear shadows on the sand, enhancing the sense of space and reality in the picture.\n\nThe entire scene, with its clean and transparent colors and fantasy settings, not only exudes the vastness of the natural wilderness but also presents a quiet and poetic high-fashion sense due to the surreal vegetation."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 69,
      "type": "KSampler",
      "pos": [
        1035.333397169572,
        -48.66668116687845
      ],
      "size": [
        310,
        435
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 74
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 75
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 83
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 77
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            72
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        909396553000551,
        "randomize",
        25,
        4,
        "res_multistep",
        "simple",
        1
      ]
    },
    {
      "id": 68,
      "type": "EmptySD3LatentImage",
      "pos": [
        280.3333893440612,
        321.3333573663614
      ],
      "size": [
        260,
        98
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            77
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "EmptySD3LatentImage",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 63,
      "type": "VAELoader",
      "pos": [
        270.33337313052357,
        161.33337863358537
      ],
      "size": [
        270,
        50
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            73
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "ae.safetensors"
      ]
    },
    {
      "id": 62,
      "type": "CLIPLoader",
      "pos": [
        270.33337313052357,
        11.333322553071866
      ],
      "size": [
        270,
        98
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            78,
            82
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_3_4b.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "qwen_3_4b.safetensors",
        "lumina2",
        "default"
      ]
    },
    {
      "id": 66,
      "type": "UNETLoader",
      "pos": [
        270.33337313052357,
        -118.6667011003664
      ],
      "size": [
        270,
        74
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            71
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "z_image_bf16.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image/resolve/main/split_files/diffusion_models/z_image_bf16.safetensors",
            "directory": "diffusion_models"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        "z_image_bf16.safetensors",
        "default"
      ]
    },
    {
      "id": 35,
      "type": "MarkdownNote",
      "pos": [
        -289.6666459954674,
        -158.6666723932416
      ],
      "size": [
        510,
        420
      ],
      "flags": {
        "collapsed": false
      },
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model link (for local users)",
      "properties": {},
      "widgets_values": [
        "## Model links\n\n**text_encoders**\n\n- [qwen_3_4b.safetensors](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors)\n\n**diffusion_models**\n\n- [z_image_bf16.safetensors](https://huggingface.co/Comfy-Org/z_image/resolve/main/split_files/diffusion_models/z_image_bf16.safetensors)\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors)\n\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ text_encoders/\nâ”‚   â”‚      â””â”€â”€ qwen_3_4b.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚      â””â”€â”€ z_image_bf16.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ vae/\nâ”‚          â””â”€â”€ ae.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#000"
    },
    {
      "id": 71,
      "type": "CLIPTextEncode",
      "pos": [
        590,
        250
      ],
      "size": [
        390,
        125
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 82
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            83
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.73",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": [
        ""
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 72,
      "type": "MarkdownNote",
      "pos": [
        1040,
        440
      ],
      "size": [
        300,
        52
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Settings",
      "properties": {},
      "widgets_values": [
        "- Steps: 30ï½ž50\n- cfg:  3ï½ž5"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 65,
      "type": "VAEDecode",
      "pos": [
        1380,
        -160
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 72
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 73
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            79
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65
      },
      "widgets_values": []
    }
  ],
  "links": [
    [
      71,
      66,
      0,
      70,
      0,
      "MODEL"
    ],
    [
      72,
      69,
      0,
      65,
      0,
      "LATENT"
    ],
    [
      73,
      63,
      0,
      65,
      1,
      "VAE"
    ],
    [
      74,
      70,
      0,
      69,
      0,
      "MODEL"
    ],
    [
      75,
      67,
      0,
      69,
      1,
      "CONDITIONING"
    ],
    [
      77,
      68,
      0,
      69,
      3,
      "LATENT"
    ],
    [
      78,
      62,
      0,
      67,
      0,
      "CLIP"
    ],
    [
      79,
      65,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      82,
      62,
      0,
      71,
      0,
      "CLIP"
    ],
    [
      83,
      71,
      0,
      69,
      2,
      "CONDITIONING"
    ]
  ],
  "groups": [
    {
      "id": 2,
      "title": "Step2 - Image size",
      "bounding": [
        260.3333367785333,
        241.33333237890417,
        290,
        200
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        570.3333367785333,
        -188.66666762109583,
        440,
        630
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Step1 - Load models",
      "bounding": [
        260.3333367785333,
        -188.66666762109583,
        290,
        413.6
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.539136280440646,
      "offset": [
        367.82528451977873,
        797.9184996280613
      ]
    },
    "frontendVersion": "1.37.11",
    "workflowRendererVersion": "LG",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}